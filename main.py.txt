
import streamlit as st
import torch
import torch.nn as nn
from PIL import Image
import os
import glob
import logging
import warnings
import mediapipe as mp
import numpy as np
import cv2
import gc
import time
from contextlib import contextmanager

from feature_visualization import get_feature_maps, display_feature_maps
from video_processor import VideoProcessor
from data_handler import get_transforms
from train_efficientnet import DeepfakeEfficientNet

# Constants
MODEL_IMAGE_SIZES = {
    "efficientnet": 300,
}
SESSION_TIMEOUT = 3600
LAST_ACTIVITY_KEY = "last_activity"
SESSION_DATA_KEY = "session_data"

# Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(_name_)

# Warnings suppression
warnings.filterwarnings('ignore', category=UserWarning, module='timm')
warnings.filterwarnings('ignore', category=UserWarning, module='huggingface_hub')
warnings.filterwarnings('ignore', category=FutureWarning, module='torch.serialization')

# MediaPipe Init
mp_face_detection = mp.solutions.face_detection
mp_drawing = mp.solutions.drawing_utils

# Page setup
st.set_page_config(page_title="Morphing Detection", layout="wide")

@contextmanager
def cleanup_on_exit():
    try:
        yield
    finally:
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()

def init_session_state():
    if LAST_ACTIVITY_KEY not in st.session_state:
        st.session_state[LAST_ACTIVITY_KEY] = time.time()
    if SESSION_DATA_KEY not in st.session_state:
        st.session_state[SESSION_DATA_KEY] = {}
    st.session_state[LAST_ACTIVITY_KEY] = time.time()

def check_session_timeout():
    if LAST_ACTIVITY_KEY in st.session_state:
        if time.time() - st.session_state[LAST_ACTIVITY_KEY] > SESSION_TIMEOUT:
            st.session_state[SESSION_DATA_KEY] = {}
            st.session_state[LAST_ACTIVITY_KEY] = time.time()
            return True
    return False

def clear_session_data():
    if SESSION_DATA_KEY in st.session_state:
        st.session_state[SESSION_DATA_KEY] = {}
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    gc.collect()

@st.cache_resource
def get_cached_model(model_path, model_type):
    try:
        model = None
        if model_type == "efficientnet":
            model = DeepfakeEfficientNet()
        if model is None:
            return None
        state_dict = torch.load(model_path, map_location='cpu')
        model.load_state_dict(state_dict, strict=False)
        model.eval()
        return model
    except Exception as e:
        return None

def extract_face(image, padding=0.1):
    img_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
    height, width = img_cv.shape[:2]
    with mp_face_detection.FaceDetection(min_detection_confidence=0.5, model_selection=1) as face_detection:
        results = face_detection.process(cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB))
        if not results.detections:
            return None, None
        detection = results.detections[0]
        bbox = detection.location_data.relative_bounding_box
        pad_w = max(int(bbox.width * width * padding), 0)
        pad_h = max(int(bbox.height * height * padding), 0)
        x = max(0, int(bbox.xmin * width) - pad_w)
        y = max(0, int(bbox.ymin * height) - pad_h)
        w = min(int(bbox.width * width) + (2 * pad_w), width - x)
        h = min(int(bbox.height * height) + (2 * pad_h), height - y)
        if w <= 0 or h <= 0 or x >= width or y >= height:
            return None, None
        try:
            face_region = img_cv[y:y+h, x:x+w]
            if face_region.size == 0:
                return None, None
            face_region_rgb = cv2.cvtColor(face_region, cv2.COLOR_BGR2RGB)
            face_pil = Image.fromarray(face_region_rgb)
            img_cv_viz = img_cv.copy()
            cv2.rectangle(img_cv_viz, (x, y), (x+w, y+h), (0, 255, 0), 2)
            img_viz = cv2.cvtColor(img_cv_viz, cv2.COLOR_BGR2RGB)
            return face_pil, Image.fromarray(img_viz)
        except Exception as e:
            logger.error(f"Error in face extraction: {str(e)}")
            return None, None

def process_image(image, model_type):
    try:
        img_size = MODEL_IMAGE_SIZES.get(model_type, 224)
        transform = get_transforms(img_size)
        transformed_image = transform(image).unsqueeze(0)
        logger.info(f"Successfully processed image for {model_type} (size: {img_size})")
        return transformed_image
    except Exception as e:
        logger.error(f"Error processing image: {str(e)}")
        return None

def format_prediction(prob):
    label = "FAKE" if prob > 0.5 else "REAL"
    confidence = prob if label == "FAKE" else 1 - prob
    return label, confidence

def main():
    init_session_state()
    if check_session_timeout():
        st.warning("Session timed out. Reload page.")
        return

    st.title("Morphing Detection System")
    input_type = st.radio("Select input type:", ["Image", "Video"], horizontal=True)

    if input_type == "Image":
        uploaded_file = st.file_uploader("Upload an image", type=["jpg", "jpeg", "png"])
        if uploaded_file:
            with cleanup_on_exit():
                image = Image.open(uploaded_file).convert('RGB')
                face_img, viz_img = extract_face(image)
                if not face_img:
                    st.error("No face detected")
                    return
                st.image(viz_img, caption="Detected Face")

                model_path = "converted_models/efficientnet_morphing.pt"
                model_type = "efficientnet"
                model = get_cached_model(model_path, model_type)
                if not model:
                    st.error("Model could not be loaded")
                    return
                image_tensor = process_image(face_img, model_type)
                with torch.no_grad():
                    output = model(image_tensor)
                    prob = torch.sigmoid(output).item()
                    label, conf = format_prediction(prob)
                    st.markdown(f"*Prediction:* {label} ({conf:.2%} confidence)")

                with st.expander("Show Feature Maps"):
                    feature_maps = get_feature_maps(model, model_type, image_tensor)
                    display_feature_maps(face_img, feature_maps)

    else:
        uploaded_file = st.file_uploader("Upload a video", type=["mp4", "avi", "mov"])
        if uploaded_file:
            with cleanup_on_exit():
                st.warning("Video processing logic is under development.")

if _name_ == "_main_":
    main()